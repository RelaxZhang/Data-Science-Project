{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A 1-D LSTM model:\n",
    "1. Split the train/validation/test dataset. (can remove the validation set)\n",
    "2. Re-arrange the input data: use year, SA3code and total population. For each column, it shows the the total pop for this area during the whole time range.\n",
    "3. Fit the model and predict on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "\n",
    "def split_ts_data(data, val_start, test_start):\n",
    "    year_min = min(data['Year'])\n",
    "    year_max = max(data['Year'])\n",
    "    year_range = year_max-year_min\n",
    "    \n",
    "    assert (val_start >= year_min) & (test_start >= year_min) & (val_start <= year_max) & (test_start <= year_max), \"Parameter out of bounds\"\n",
    "    assert (val_start > year_min) & (test_start > year_min), \"Training set is empty.\"\n",
    "    assert val_start < test_start, \"Validation set is empty.\"\n",
    "    assert year_range > 0, \"Data contains less than 2 years.\"\n",
    "    \n",
    "    \n",
    "    train_data = data[(data['Year']<val_start) & (data['Year']<test_start)]\n",
    "    val_data = data[(data['Year']>=val_start) & (data['Year']<test_start)]\n",
    "    test_data = data[data['Year']>=test_start]\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df, input_width, label_width, shift):\n",
    "    def create_window(tensor):\n",
    "        #input -> length of time series used for training\n",
    "        #shift -> how far off prediction is from last input\n",
    "        #label -> points to predict\n",
    "        total_window_size = input_width + shift\n",
    "        label_start = total_window_size - label_width\n",
    "\n",
    "        input_bounds = slice(0, input_width)\n",
    "        label_bounds = slice(label_start, None)\n",
    "\n",
    "        inputs = tensor[:,input_bounds,:]\n",
    "        labels = tensor[:,label_bounds,:]\n",
    "\n",
    "        inputs.set_shape([None, input_width, None])\n",
    "        labels.set_shape([None, label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    total_window_size = input_width + shift\n",
    "    \n",
    "    arr = np.array(df, dtype=np.float32)\n",
    "    ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=arr,\n",
    "      targets=None,\n",
    "      sequence_length=total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32,)\n",
    "    \n",
    "    ds = ds.map(create_window)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, epochs, input_optimizer='adam', input_loss='mse'):\n",
    "    model.compile(optimizer=input_optimizer, loss=input_loss)\n",
    "    history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_dict(np_df):\n",
    "    return_dict = {col:index for index, col in enumerate(np_df.columns)}\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, ds, input_width, label_width, shift, model=None, plot_col='10101 m0.4', max_subplots=3):\n",
    "    #ensure that df and ds match e.g. train_df must be accompanied by train_ds\n",
    "    col_indices = col_dict(df)\n",
    "    \n",
    "    total_window_size = label_width + shift\n",
    "    input_slice = slice(0,input_width)\n",
    "    input_indices = np.arange(total_window_size)[input_slice]\n",
    "    label_start = total_window_size - label_width\n",
    "    labels_slice = slice(label_start, None)\n",
    "    label_indices = np.arange(total_window_size)[labels_slice]\n",
    "    \n",
    "    inputs = next(iter(ds))[0]\n",
    "    labels = next(iter(ds))[1]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = col_indices[plot_col] \n",
    "    max_n = min(max_subplots, len(inputs))\n",
    "    \n",
    "    for n in range(max_n):\n",
    "        plt.subplot(max_n, 1, n+1)\n",
    "        plt.ylabel(plot_col)\n",
    "        plt.plot(input_indices, inputs[n, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "        \n",
    "        plt.scatter(label_indices, labels[n, :, plot_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "        \n",
    "        if model is not None:\n",
    "          predictions = model(inputs)\n",
    "          plt.scatter(label_indices, predictions[n, :, plot_col_index],\n",
    "                  marker='X', edgecolors='k', label='Predictions',\n",
    "                  c='#ff7f0e', s=64)\n",
    "            \n",
    "        if n == 0:\n",
    "          plt.legend()\n",
    "        \n",
    "    plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit parameters here, but do not rename variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read, preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('newSA3.csv')\n",
    "\n",
    "\n",
    "\n",
    "#Parameters\n",
    "validation_start = 2002\n",
    "test_start = 2006\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = split_ts_data(raw_data, validation_start, test_start)\n",
    "\n",
    "train_df = train_df[train_df.columns.difference([\"Unnamed: 0\",\"Year\"])]\n",
    "val_df = val_df[val_df.columns.difference([\"Unnamed: 0\",\"Year\"])]\n",
    "test_df = test_df[test_df.columns.difference([\"Unnamed: 0\",\"Year\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>10101 m0.4</th>\n",
       "      <th>10102 m0.4</th>\n",
       "      <th>10103 m0.4</th>\n",
       "      <th>10104 m0.4</th>\n",
       "      <th>10201 m0.4</th>\n",
       "      <th>10202 m0.4</th>\n",
       "      <th>10301 m0.4</th>\n",
       "      <th>10302 m0.4</th>\n",
       "      <th>...</th>\n",
       "      <th>70203 f85.</th>\n",
       "      <th>70204 f85.</th>\n",
       "      <th>70205 f85.</th>\n",
       "      <th>80101 f85.</th>\n",
       "      <th>80103 f85.</th>\n",
       "      <th>80105 f85.</th>\n",
       "      <th>80106 f85.</th>\n",
       "      <th>80107 f85.</th>\n",
       "      <th>80108 f85.</th>\n",
       "      <th>80109 f85.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>2603</td>\n",
       "      <td>1593</td>\n",
       "      <td>741</td>\n",
       "      <td>1985</td>\n",
       "      <td>5373</td>\n",
       "      <td>4332</td>\n",
       "      <td>1530</td>\n",
       "      <td>2621</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>196</td>\n",
       "      <td>41</td>\n",
       "      <td>91</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1992</td>\n",
       "      <td>2605</td>\n",
       "      <td>1625</td>\n",
       "      <td>740</td>\n",
       "      <td>1962</td>\n",
       "      <td>5504</td>\n",
       "      <td>4503</td>\n",
       "      <td>1522</td>\n",
       "      <td>2615</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>6</td>\n",
       "      <td>180</td>\n",
       "      <td>201</td>\n",
       "      <td>49</td>\n",
       "      <td>93</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1993</td>\n",
       "      <td>2585</td>\n",
       "      <td>1638</td>\n",
       "      <td>736</td>\n",
       "      <td>1920</td>\n",
       "      <td>5577</td>\n",
       "      <td>4620</td>\n",
       "      <td>1496</td>\n",
       "      <td>2580</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>9</td>\n",
       "      <td>191</td>\n",
       "      <td>221</td>\n",
       "      <td>58</td>\n",
       "      <td>103</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>2557</td>\n",
       "      <td>1643</td>\n",
       "      <td>728</td>\n",
       "      <td>1873</td>\n",
       "      <td>5620</td>\n",
       "      <td>4716</td>\n",
       "      <td>1474</td>\n",
       "      <td>2540</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>199</td>\n",
       "      <td>11</td>\n",
       "      <td>198</td>\n",
       "      <td>230</td>\n",
       "      <td>65</td>\n",
       "      <td>107</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "      <td>2508</td>\n",
       "      <td>1631</td>\n",
       "      <td>714</td>\n",
       "      <td>1803</td>\n",
       "      <td>5632</td>\n",
       "      <td>4772</td>\n",
       "      <td>1442</td>\n",
       "      <td>2470</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>221</td>\n",
       "      <td>15</td>\n",
       "      <td>201</td>\n",
       "      <td>244</td>\n",
       "      <td>69</td>\n",
       "      <td>114</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Year  10101 m0.4  10102 m0.4  10103 m0.4  10104 m0.4  \\\n",
       "0           1  1991        2603        1593         741        1985   \n",
       "1           2  1992        2605        1625         740        1962   \n",
       "2           3  1993        2585        1638         736        1920   \n",
       "3           4  1994        2557        1643         728        1873   \n",
       "4           5  1995        2508        1631         714        1803   \n",
       "\n",
       "   10201 m0.4  10202 m0.4  10301 m0.4  10302 m0.4  ...  70203 f85.  \\\n",
       "0        5373        4332        1530        2621  ...           4   \n",
       "1        5504        4503        1522        2615  ...           6   \n",
       "2        5577        4620        1496        2580  ...           8   \n",
       "3        5620        4716        1474        2540  ...          12   \n",
       "4        5632        4772        1442        2470  ...          16   \n",
       "\n",
       "   70204 f85.  70205 f85.  80101 f85.  80103 f85.  80105 f85.  80106 f85.  \\\n",
       "0           2           5         145           2         178         196   \n",
       "1           5           6         164           6         180         201   \n",
       "2           6           7         187           9         191         221   \n",
       "3           9           8         199          11         198         230   \n",
       "4          13          10         221          15         201         244   \n",
       "\n",
       "   80107 f85.  80108 f85.  80109 f85.  \n",
       "0          41          91         116  \n",
       "1          49          93         134  \n",
       "2          58         103         154  \n",
       "3          65         107         171  \n",
       "4          69         114         190  \n",
       "\n",
       "[5 rows x 11702 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10101 f0.4</th>\n",
       "      <th>10101 f10.14</th>\n",
       "      <th>10101 f15.19</th>\n",
       "      <th>10101 f20.24</th>\n",
       "      <th>10101 f25.29</th>\n",
       "      <th>10101 f30.34</th>\n",
       "      <th>10101 f35.39</th>\n",
       "      <th>10101 f40.44</th>\n",
       "      <th>10101 f45.49</th>\n",
       "      <th>10101 f5.9</th>\n",
       "      <th>...</th>\n",
       "      <th>80109 m45.49</th>\n",
       "      <th>80109 m5.9</th>\n",
       "      <th>80109 m50.54</th>\n",
       "      <th>80109 m55.59</th>\n",
       "      <th>80109 m60.64</th>\n",
       "      <th>80109 m65.69</th>\n",
       "      <th>80109 m70.74</th>\n",
       "      <th>80109 m75.79</th>\n",
       "      <th>80109 m80.84</th>\n",
       "      <th>80109 m85.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2400</td>\n",
       "      <td>2347</td>\n",
       "      <td>2277</td>\n",
       "      <td>1820</td>\n",
       "      <td>2152</td>\n",
       "      <td>2315</td>\n",
       "      <td>2185</td>\n",
       "      <td>2146</td>\n",
       "      <td>1859</td>\n",
       "      <td>2495</td>\n",
       "      <td>...</td>\n",
       "      <td>1219</td>\n",
       "      <td>1002</td>\n",
       "      <td>1226</td>\n",
       "      <td>920</td>\n",
       "      <td>784</td>\n",
       "      <td>606</td>\n",
       "      <td>328</td>\n",
       "      <td>180</td>\n",
       "      <td>98</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2392</td>\n",
       "      <td>2344</td>\n",
       "      <td>2194</td>\n",
       "      <td>1830</td>\n",
       "      <td>2067</td>\n",
       "      <td>2339</td>\n",
       "      <td>2204</td>\n",
       "      <td>2139</td>\n",
       "      <td>1954</td>\n",
       "      <td>2480</td>\n",
       "      <td>...</td>\n",
       "      <td>1257</td>\n",
       "      <td>1009</td>\n",
       "      <td>1209</td>\n",
       "      <td>931</td>\n",
       "      <td>794</td>\n",
       "      <td>617</td>\n",
       "      <td>376</td>\n",
       "      <td>200</td>\n",
       "      <td>104</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2382</td>\n",
       "      <td>2354</td>\n",
       "      <td>2126</td>\n",
       "      <td>1813</td>\n",
       "      <td>1977</td>\n",
       "      <td>2329</td>\n",
       "      <td>2225</td>\n",
       "      <td>2139</td>\n",
       "      <td>2037</td>\n",
       "      <td>2451</td>\n",
       "      <td>...</td>\n",
       "      <td>1285</td>\n",
       "      <td>993</td>\n",
       "      <td>1154</td>\n",
       "      <td>963</td>\n",
       "      <td>792</td>\n",
       "      <td>634</td>\n",
       "      <td>413</td>\n",
       "      <td>209</td>\n",
       "      <td>105</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2357</td>\n",
       "      <td>2351</td>\n",
       "      <td>2084</td>\n",
       "      <td>1777</td>\n",
       "      <td>1913</td>\n",
       "      <td>2316</td>\n",
       "      <td>2232</td>\n",
       "      <td>2158</td>\n",
       "      <td>2079</td>\n",
       "      <td>2418</td>\n",
       "      <td>...</td>\n",
       "      <td>1284</td>\n",
       "      <td>988</td>\n",
       "      <td>1123</td>\n",
       "      <td>998</td>\n",
       "      <td>778</td>\n",
       "      <td>649</td>\n",
       "      <td>459</td>\n",
       "      <td>212</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2318</td>\n",
       "      <td>2357</td>\n",
       "      <td>2055</td>\n",
       "      <td>1734</td>\n",
       "      <td>1869</td>\n",
       "      <td>2272</td>\n",
       "      <td>2256</td>\n",
       "      <td>2165</td>\n",
       "      <td>2111</td>\n",
       "      <td>2403</td>\n",
       "      <td>...</td>\n",
       "      <td>1277</td>\n",
       "      <td>998</td>\n",
       "      <td>1105</td>\n",
       "      <td>1020</td>\n",
       "      <td>819</td>\n",
       "      <td>648</td>\n",
       "      <td>486</td>\n",
       "      <td>247</td>\n",
       "      <td>116</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2280</td>\n",
       "      <td>2360</td>\n",
       "      <td>2060</td>\n",
       "      <td>1656</td>\n",
       "      <td>1869</td>\n",
       "      <td>2218</td>\n",
       "      <td>2290</td>\n",
       "      <td>2186</td>\n",
       "      <td>2150</td>\n",
       "      <td>2400</td>\n",
       "      <td>...</td>\n",
       "      <td>1244</td>\n",
       "      <td>1015</td>\n",
       "      <td>1112</td>\n",
       "      <td>1051</td>\n",
       "      <td>833</td>\n",
       "      <td>672</td>\n",
       "      <td>513</td>\n",
       "      <td>277</td>\n",
       "      <td>124</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2242</td>\n",
       "      <td>2327</td>\n",
       "      <td>2054</td>\n",
       "      <td>1555</td>\n",
       "      <td>1905</td>\n",
       "      <td>2104</td>\n",
       "      <td>2340</td>\n",
       "      <td>2208</td>\n",
       "      <td>2153</td>\n",
       "      <td>2393</td>\n",
       "      <td>...</td>\n",
       "      <td>1188</td>\n",
       "      <td>985</td>\n",
       "      <td>1117</td>\n",
       "      <td>1086</td>\n",
       "      <td>835</td>\n",
       "      <td>676</td>\n",
       "      <td>527</td>\n",
       "      <td>316</td>\n",
       "      <td>123</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2171</td>\n",
       "      <td>2338</td>\n",
       "      <td>2051</td>\n",
       "      <td>1480</td>\n",
       "      <td>1912</td>\n",
       "      <td>2054</td>\n",
       "      <td>2403</td>\n",
       "      <td>2171</td>\n",
       "      <td>2153</td>\n",
       "      <td>2400</td>\n",
       "      <td>...</td>\n",
       "      <td>1157</td>\n",
       "      <td>975</td>\n",
       "      <td>1127</td>\n",
       "      <td>1083</td>\n",
       "      <td>847</td>\n",
       "      <td>690</td>\n",
       "      <td>572</td>\n",
       "      <td>358</td>\n",
       "      <td>142</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2132</td>\n",
       "      <td>2348</td>\n",
       "      <td>2039</td>\n",
       "      <td>1450</td>\n",
       "      <td>1892</td>\n",
       "      <td>2005</td>\n",
       "      <td>2395</td>\n",
       "      <td>2217</td>\n",
       "      <td>2195</td>\n",
       "      <td>2400</td>\n",
       "      <td>...</td>\n",
       "      <td>1149</td>\n",
       "      <td>975</td>\n",
       "      <td>1123</td>\n",
       "      <td>1051</td>\n",
       "      <td>851</td>\n",
       "      <td>694</td>\n",
       "      <td>598</td>\n",
       "      <td>389</td>\n",
       "      <td>163</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2107</td>\n",
       "      <td>2335</td>\n",
       "      <td>2029</td>\n",
       "      <td>1452</td>\n",
       "      <td>1848</td>\n",
       "      <td>1991</td>\n",
       "      <td>2363</td>\n",
       "      <td>2251</td>\n",
       "      <td>2201</td>\n",
       "      <td>2393</td>\n",
       "      <td>...</td>\n",
       "      <td>1122</td>\n",
       "      <td>967</td>\n",
       "      <td>1163</td>\n",
       "      <td>997</td>\n",
       "      <td>892</td>\n",
       "      <td>717</td>\n",
       "      <td>577</td>\n",
       "      <td>439</td>\n",
       "      <td>190</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2077</td>\n",
       "      <td>2259</td>\n",
       "      <td>2051</td>\n",
       "      <td>1467</td>\n",
       "      <td>1777</td>\n",
       "      <td>1997</td>\n",
       "      <td>2263</td>\n",
       "      <td>2282</td>\n",
       "      <td>2203</td>\n",
       "      <td>2302</td>\n",
       "      <td>...</td>\n",
       "      <td>1100</td>\n",
       "      <td>945</td>\n",
       "      <td>1200</td>\n",
       "      <td>996</td>\n",
       "      <td>898</td>\n",
       "      <td>676</td>\n",
       "      <td>596</td>\n",
       "      <td>457</td>\n",
       "      <td>221</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 11700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10101 f0.4  10101 f10.14  10101 f15.19  10101 f20.24  10101 f25.29  \\\n",
       "0         2400          2347          2277          1820          2152   \n",
       "1         2392          2344          2194          1830          2067   \n",
       "2         2382          2354          2126          1813          1977   \n",
       "3         2357          2351          2084          1777          1913   \n",
       "4         2318          2357          2055          1734          1869   \n",
       "5         2280          2360          2060          1656          1869   \n",
       "6         2242          2327          2054          1555          1905   \n",
       "7         2171          2338          2051          1480          1912   \n",
       "8         2132          2348          2039          1450          1892   \n",
       "9         2107          2335          2029          1452          1848   \n",
       "10        2077          2259          2051          1467          1777   \n",
       "\n",
       "    10101 f30.34  10101 f35.39  10101 f40.44  10101 f45.49  10101 f5.9  ...  \\\n",
       "0           2315          2185          2146          1859        2495  ...   \n",
       "1           2339          2204          2139          1954        2480  ...   \n",
       "2           2329          2225          2139          2037        2451  ...   \n",
       "3           2316          2232          2158          2079        2418  ...   \n",
       "4           2272          2256          2165          2111        2403  ...   \n",
       "5           2218          2290          2186          2150        2400  ...   \n",
       "6           2104          2340          2208          2153        2393  ...   \n",
       "7           2054          2403          2171          2153        2400  ...   \n",
       "8           2005          2395          2217          2195        2400  ...   \n",
       "9           1991          2363          2251          2201        2393  ...   \n",
       "10          1997          2263          2282          2203        2302  ...   \n",
       "\n",
       "    80109 m45.49  80109 m5.9  80109 m50.54  80109 m55.59  80109 m60.64  \\\n",
       "0           1219        1002          1226           920           784   \n",
       "1           1257        1009          1209           931           794   \n",
       "2           1285         993          1154           963           792   \n",
       "3           1284         988          1123           998           778   \n",
       "4           1277         998          1105          1020           819   \n",
       "5           1244        1015          1112          1051           833   \n",
       "6           1188         985          1117          1086           835   \n",
       "7           1157         975          1127          1083           847   \n",
       "8           1149         975          1123          1051           851   \n",
       "9           1122         967          1163           997           892   \n",
       "10          1100         945          1200           996           898   \n",
       "\n",
       "    80109 m65.69  80109 m70.74  80109 m75.79  80109 m80.84  80109 m85.  \n",
       "0            606           328           180            98          50  \n",
       "1            617           376           200           104          55  \n",
       "2            634           413           209           105          59  \n",
       "3            649           459           212           112          65  \n",
       "4            648           486           247           116          69  \n",
       "5            672           513           277           124          74  \n",
       "6            676           527           316           123          79  \n",
       "7            690           572           358           142          88  \n",
       "8            694           598           389           163          95  \n",
       "9            717           577           439           190         103  \n",
       "10           676           596           457           221         119  \n",
       "\n",
       "[11 rows x 11700 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10101 f0.4</th>\n",
       "      <th>10101 f10.14</th>\n",
       "      <th>10101 f15.19</th>\n",
       "      <th>10101 f20.24</th>\n",
       "      <th>10101 f25.29</th>\n",
       "      <th>10101 f30.34</th>\n",
       "      <th>10101 f35.39</th>\n",
       "      <th>10101 f40.44</th>\n",
       "      <th>10101 f45.49</th>\n",
       "      <th>10101 f5.9</th>\n",
       "      <th>...</th>\n",
       "      <th>80109 m45.49</th>\n",
       "      <th>80109 m5.9</th>\n",
       "      <th>80109 m50.54</th>\n",
       "      <th>80109 m55.59</th>\n",
       "      <th>80109 m60.64</th>\n",
       "      <th>80109 m65.69</th>\n",
       "      <th>80109 m70.74</th>\n",
       "      <th>80109 m75.79</th>\n",
       "      <th>80109 m80.84</th>\n",
       "      <th>80109 m85.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2068</td>\n",
       "      <td>2272</td>\n",
       "      <td>2072</td>\n",
       "      <td>1450</td>\n",
       "      <td>1682</td>\n",
       "      <td>2080</td>\n",
       "      <td>2189</td>\n",
       "      <td>2323</td>\n",
       "      <td>2239</td>\n",
       "      <td>2319</td>\n",
       "      <td>...</td>\n",
       "      <td>1114</td>\n",
       "      <td>984</td>\n",
       "      <td>1132</td>\n",
       "      <td>986</td>\n",
       "      <td>960</td>\n",
       "      <td>692</td>\n",
       "      <td>590</td>\n",
       "      <td>452</td>\n",
       "      <td>253</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2033</td>\n",
       "      <td>2317</td>\n",
       "      <td>2078</td>\n",
       "      <td>1466</td>\n",
       "      <td>1622</td>\n",
       "      <td>2116</td>\n",
       "      <td>2172</td>\n",
       "      <td>2394</td>\n",
       "      <td>2217</td>\n",
       "      <td>2299</td>\n",
       "      <td>...</td>\n",
       "      <td>1115</td>\n",
       "      <td>990</td>\n",
       "      <td>1078</td>\n",
       "      <td>1003</td>\n",
       "      <td>920</td>\n",
       "      <td>713</td>\n",
       "      <td>601</td>\n",
       "      <td>454</td>\n",
       "      <td>285</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2035</td>\n",
       "      <td>2372</td>\n",
       "      <td>2058</td>\n",
       "      <td>1481</td>\n",
       "      <td>1585</td>\n",
       "      <td>2089</td>\n",
       "      <td>2152</td>\n",
       "      <td>2419</td>\n",
       "      <td>2220</td>\n",
       "      <td>2256</td>\n",
       "      <td>...</td>\n",
       "      <td>1136</td>\n",
       "      <td>978</td>\n",
       "      <td>1065</td>\n",
       "      <td>993</td>\n",
       "      <td>887</td>\n",
       "      <td>728</td>\n",
       "      <td>584</td>\n",
       "      <td>476</td>\n",
       "      <td>298</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2038</td>\n",
       "      <td>2406</td>\n",
       "      <td>2052</td>\n",
       "      <td>1520</td>\n",
       "      <td>1571</td>\n",
       "      <td>2025</td>\n",
       "      <td>2171</td>\n",
       "      <td>2403</td>\n",
       "      <td>2240</td>\n",
       "      <td>2216</td>\n",
       "      <td>...</td>\n",
       "      <td>1192</td>\n",
       "      <td>979</td>\n",
       "      <td>1027</td>\n",
       "      <td>1030</td>\n",
       "      <td>828</td>\n",
       "      <td>754</td>\n",
       "      <td>599</td>\n",
       "      <td>471</td>\n",
       "      <td>313</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 11700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10101 f0.4  10101 f10.14  10101 f15.19  10101 f20.24  10101 f25.29  \\\n",
       "11        2068          2272          2072          1450          1682   \n",
       "12        2033          2317          2078          1466          1622   \n",
       "13        2035          2372          2058          1481          1585   \n",
       "14        2038          2406          2052          1520          1571   \n",
       "\n",
       "    10101 f30.34  10101 f35.39  10101 f40.44  10101 f45.49  10101 f5.9  ...  \\\n",
       "11          2080          2189          2323          2239        2319  ...   \n",
       "12          2116          2172          2394          2217        2299  ...   \n",
       "13          2089          2152          2419          2220        2256  ...   \n",
       "14          2025          2171          2403          2240        2216  ...   \n",
       "\n",
       "    80109 m45.49  80109 m5.9  80109 m50.54  80109 m55.59  80109 m60.64  \\\n",
       "11          1114         984          1132           986           960   \n",
       "12          1115         990          1078          1003           920   \n",
       "13          1136         978          1065           993           887   \n",
       "14          1192         979          1027          1030           828   \n",
       "\n",
       "    80109 m65.69  80109 m70.74  80109 m75.79  80109 m80.84  80109 m85.  \n",
       "11           692           590           452           253         128  \n",
       "12           713           601           454           285         127  \n",
       "13           728           584           476           298         129  \n",
       "14           754           599           471           313         156  \n",
       "\n",
       "[4 rows x 11700 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10101 f0.4</th>\n",
       "      <th>10101 f10.14</th>\n",
       "      <th>10101 f15.19</th>\n",
       "      <th>10101 f20.24</th>\n",
       "      <th>10101 f25.29</th>\n",
       "      <th>10101 f30.34</th>\n",
       "      <th>10101 f35.39</th>\n",
       "      <th>10101 f40.44</th>\n",
       "      <th>10101 f45.49</th>\n",
       "      <th>10101 f5.9</th>\n",
       "      <th>...</th>\n",
       "      <th>80109 m45.49</th>\n",
       "      <th>80109 m5.9</th>\n",
       "      <th>80109 m50.54</th>\n",
       "      <th>80109 m55.59</th>\n",
       "      <th>80109 m60.64</th>\n",
       "      <th>80109 m65.69</th>\n",
       "      <th>80109 m70.74</th>\n",
       "      <th>80109 m75.79</th>\n",
       "      <th>80109 m80.84</th>\n",
       "      <th>80109 m85.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2005</td>\n",
       "      <td>2428</td>\n",
       "      <td>2034</td>\n",
       "      <td>1570</td>\n",
       "      <td>1566</td>\n",
       "      <td>1936</td>\n",
       "      <td>2246</td>\n",
       "      <td>2337</td>\n",
       "      <td>2292</td>\n",
       "      <td>2232</td>\n",
       "      <td>...</td>\n",
       "      <td>1248</td>\n",
       "      <td>992</td>\n",
       "      <td>1030</td>\n",
       "      <td>1031</td>\n",
       "      <td>795</td>\n",
       "      <td>771</td>\n",
       "      <td>589</td>\n",
       "      <td>499</td>\n",
       "      <td>325</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011</td>\n",
       "      <td>2375</td>\n",
       "      <td>2112</td>\n",
       "      <td>1542</td>\n",
       "      <td>1583</td>\n",
       "      <td>1875</td>\n",
       "      <td>2288</td>\n",
       "      <td>2247</td>\n",
       "      <td>2352</td>\n",
       "      <td>2210</td>\n",
       "      <td>...</td>\n",
       "      <td>1279</td>\n",
       "      <td>962</td>\n",
       "      <td>1042</td>\n",
       "      <td>988</td>\n",
       "      <td>798</td>\n",
       "      <td>818</td>\n",
       "      <td>599</td>\n",
       "      <td>480</td>\n",
       "      <td>356</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2044</td>\n",
       "      <td>2343</td>\n",
       "      <td>2145</td>\n",
       "      <td>1594</td>\n",
       "      <td>1640</td>\n",
       "      <td>1840</td>\n",
       "      <td>2314</td>\n",
       "      <td>2246</td>\n",
       "      <td>2418</td>\n",
       "      <td>2210</td>\n",
       "      <td>...</td>\n",
       "      <td>1283</td>\n",
       "      <td>954</td>\n",
       "      <td>1068</td>\n",
       "      <td>971</td>\n",
       "      <td>826</td>\n",
       "      <td>783</td>\n",
       "      <td>627</td>\n",
       "      <td>484</td>\n",
       "      <td>361</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2109</td>\n",
       "      <td>2330</td>\n",
       "      <td>2182</td>\n",
       "      <td>1670</td>\n",
       "      <td>1662</td>\n",
       "      <td>1857</td>\n",
       "      <td>2312</td>\n",
       "      <td>2256</td>\n",
       "      <td>2463</td>\n",
       "      <td>2213</td>\n",
       "      <td>...</td>\n",
       "      <td>1296</td>\n",
       "      <td>968</td>\n",
       "      <td>1082</td>\n",
       "      <td>975</td>\n",
       "      <td>852</td>\n",
       "      <td>768</td>\n",
       "      <td>643</td>\n",
       "      <td>481</td>\n",
       "      <td>363</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2170</td>\n",
       "      <td>2336</td>\n",
       "      <td>2230</td>\n",
       "      <td>1722</td>\n",
       "      <td>1691</td>\n",
       "      <td>1883</td>\n",
       "      <td>2274</td>\n",
       "      <td>2328</td>\n",
       "      <td>2474</td>\n",
       "      <td>2217</td>\n",
       "      <td>...</td>\n",
       "      <td>1262</td>\n",
       "      <td>983</td>\n",
       "      <td>1129</td>\n",
       "      <td>962</td>\n",
       "      <td>893</td>\n",
       "      <td>741</td>\n",
       "      <td>674</td>\n",
       "      <td>492</td>\n",
       "      <td>360</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2225</td>\n",
       "      <td>2381</td>\n",
       "      <td>2178</td>\n",
       "      <td>1698</td>\n",
       "      <td>1681</td>\n",
       "      <td>1864</td>\n",
       "      <td>2252</td>\n",
       "      <td>2426</td>\n",
       "      <td>2430</td>\n",
       "      <td>2217</td>\n",
       "      <td>...</td>\n",
       "      <td>1201</td>\n",
       "      <td>974</td>\n",
       "      <td>1194</td>\n",
       "      <td>927</td>\n",
       "      <td>867</td>\n",
       "      <td>756</td>\n",
       "      <td>716</td>\n",
       "      <td>505</td>\n",
       "      <td>414</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 11700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10101 f0.4  10101 f10.14  10101 f15.19  10101 f20.24  10101 f25.29  \\\n",
       "15        2005          2428          2034          1570          1566   \n",
       "16        2011          2375          2112          1542          1583   \n",
       "17        2044          2343          2145          1594          1640   \n",
       "18        2109          2330          2182          1670          1662   \n",
       "19        2170          2336          2230          1722          1691   \n",
       "20        2225          2381          2178          1698          1681   \n",
       "\n",
       "    10101 f30.34  10101 f35.39  10101 f40.44  10101 f45.49  10101 f5.9  ...  \\\n",
       "15          1936          2246          2337          2292        2232  ...   \n",
       "16          1875          2288          2247          2352        2210  ...   \n",
       "17          1840          2314          2246          2418        2210  ...   \n",
       "18          1857          2312          2256          2463        2213  ...   \n",
       "19          1883          2274          2328          2474        2217  ...   \n",
       "20          1864          2252          2426          2430        2217  ...   \n",
       "\n",
       "    80109 m45.49  80109 m5.9  80109 m50.54  80109 m55.59  80109 m60.64  \\\n",
       "15          1248         992          1030          1031           795   \n",
       "16          1279         962          1042           988           798   \n",
       "17          1283         954          1068           971           826   \n",
       "18          1296         968          1082           975           852   \n",
       "19          1262         983          1129           962           893   \n",
       "20          1201         974          1194           927           867   \n",
       "\n",
       "    80109 m65.69  80109 m70.74  80109 m75.79  80109 m80.84  80109 m85.  \n",
       "15           771           589           499           325         195  \n",
       "16           818           599           480           356         214  \n",
       "17           783           627           484           361         234  \n",
       "18           768           643           481           363         250  \n",
       "19           741           674           492           360         264  \n",
       "20           756           716           505           414         282  \n",
       "\n",
       "[6 rows x 11700 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "input_width = 2 #data used in prediction\n",
    "label_width = 1 #points to predict\n",
    "shift = 1 #how many years away is the last point to predict\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_df, input_width, label_width, shift)\n",
    "val_ds = make_dataset(val_df, input_width, label_width, shift)\n",
    "test_ds = make_dataset(test_df, input_width, label_width, shift)\n",
    "\n",
    "num_cols = next(iter(train_ds))[0].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4179144.5000 - val_loss: 4692178.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 4133606.2500 - val_loss: 4662759.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 4106349.0000 - val_loss: 4617698.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4075115.0000 - val_loss: 4526393.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3996172.5000 - val_loss: 4405156.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3890982.7500 - val_loss: 4277542.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3779799.0000 - val_loss: 4173783.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3683877.0000 - val_loss: 4000429.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3538824.0000 - val_loss: 3830717.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3392989.0000 - val_loss: 3644281.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b813025ca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters\n",
    "num_epochs = 10\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(50, activation='relu', return_sequences=False))\n",
    "model.add(tf.keras.layers.Dense(label_width * num_cols))\n",
    "model.add(tf.keras.layers.Reshape([label_width,num_cols]))\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "compile_and_fit(model, num_epochs, input_optimizer='adam', input_loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = next(iter(train_ds))[0]\n",
    "train_labels = next(iter(train_ds))[1]\n",
    "train_predictions = model(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1, 11700), dtype=float32, numpy=\n",
       "array([[[2382., 2354., 2126., ...,  209.,  105.,   59.]],\n",
       "\n",
       "       [[2357., 2351., 2084., ...,  212.,  112.,   65.]],\n",
       "\n",
       "       [[2318., 2357., 2055., ...,  247.,  116.,   69.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[2132., 2348., 2039., ...,  389.,  163.,   95.]],\n",
       "\n",
       "       [[2107., 2335., 2029., ...,  439.,  190.,  103.]],\n",
       "\n",
       "       [[2077., 2259., 2051., ...,  457.,  221.,  119.]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9, 1, 11700), dtype=float32, numpy=\n",
       "array([[[1817.3302 , 1086.5784 , -784.5439 , ...,  323.66547,\n",
       "          246.98868,  392.82645]],\n",
       "\n",
       "       [[1832.4203 , 1095.6006 , -791.05835, ...,  326.3529 ,\n",
       "          249.03947,  396.0883 ]],\n",
       "\n",
       "       [[1849.208  , 1105.638  , -798.30585, ...,  329.34274,\n",
       "          251.32101,  399.7171 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1939.6744 , 1159.7274 , -837.36096, ...,  345.45435,\n",
       "          263.6158 ,  419.27216]],\n",
       "\n",
       "       [[1964.3333 , 1174.4708 , -848.0064 , ...,  349.84595,\n",
       "          266.96704,  424.60236]],\n",
       "\n",
       "       [[1990.9243 , 1190.3695 , -859.486  , ...,  354.5817 ,\n",
       "          270.5809 ,  430.35022]]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = next(iter(test_ds))[0]\n",
    "test_labels = next(iter(test_ds))[1]\n",
    "test_predictions = model(test_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 11700), dtype=float32, numpy=\n",
       "array([[[2044., 2343., 2145., ...,  484.,  361.,  234.]],\n",
       "\n",
       "       [[2109., 2330., 2182., ...,  481.,  363.,  250.]],\n",
       "\n",
       "       [[2170., 2336., 2230., ...,  492.,  360.,  264.]],\n",
       "\n",
       "       [[2225., 2381., 2178., ...,  505.,  414.,  282.]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 11700), dtype=float32, numpy=\n",
       "array([[[2174.5435 , 1304.8237 , -921.7833 , ...,  370.85275,\n",
       "          298.16245,  487.31314]],\n",
       "\n",
       "       [[2217.387  , 1330.7904 , -939.0044 , ...,  377.24875,\n",
       "          304.1824 ,  497.8716 ]],\n",
       "\n",
       "       [[2263.7412 , 1359.0331 , -957.0978 , ...,  383.64737,\n",
       "          310.77902,  509.84338]],\n",
       "\n",
       "       [[2298.0193 , 1379.972  , -970.28107, ...,  388.18878,\n",
       "          315.68756,  518.89636]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step - loss: 4311915.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4311915.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10101 m0.4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_subplots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(df, ds, input_width, label_width, shift, model, plot_col, max_subplots)\u001b[0m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(max_n, \u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(plot_col)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_col_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(label_indices, labels[n, :, plot_col_index],\n\u001b[0;32m     25\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabels\u001b[39m\u001b[38;5;124m'\u001b[39m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#2ca02c\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (2,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(train_df, train_ds, input_width=1, label_width=1, shift=1, model=model, plot_col='10101 m0.4', max_subplots=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
