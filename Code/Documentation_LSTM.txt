Documentation of LSTM Model

================================================================================================================================================================================================================================
================================================================================================================================================================================================================================
1. LSTM_Iterative_Predict_Type1.ipynb

(a) Basic
(i) LSTM Defining
Defines the architecture of the LSTM model, such as the type and number of layers. Do not modify unless changing the architecture.

(ii) LSTM Tuning
Here the possible values for the hyperparameters are defined, such as the range of continuous hyperparameters or enumerations of discrete ones.
These hyperparameters can be modified as needed to change the search space for the tuner.

The build_model function is used as input for keras tuners. Here, the hyperparameter instances are defined then used alongside the model defining function.
This function should only be modified when the architecture of the model changes.

(b) Logic
Create 1-D input(population for age-group) for rolling-predicted LSTM models.
Train two models for two gender (male and female) seperately, then predict year by year. 
After refitting the latest prediction, updatte the input for next forecast.

Comment for: Preprocessing by Splitting Population into Sex-Group
Prepare the required input data for two models (male and female). 
Store population (value) for each age-group (key) into dictionary for male and female.

Comment for: Create Dataframe for Storing Prediction Result
Prepare for the output csv file that contain both gender for each age-group prediction.
Store the predicted result into the same format year-by-year.

================================================================================================================================================================================================================================
================================================================================================================================================================================================================================

2. LSTM_Iterative_Predict_Type2.ipynb

(a) Potential Methods
(i) Data Scaling
(ii) Input Data Merging / .tf Type Data Input Converting
(iii) Random Training & Validation Spliting (train_test_split from sklearn) of Full Training Set Starts from 1991 to 2001
(iv) Non-negative Processing during Rolling Prediction

(b) Applied Methods
(i) Random Training & Validation Spliting -- Validation Set weights = 0.2
Reason: Allows us to collect the more valuable information from 1999-2001 (closest to the target years) rather than having a fixed validation set from 1999-2001

(ii) Non-negative Processing -- Replace negative result from each year's predicted result during rolling updating process by 0
Reason: Population in all areas should not be negative

(c) Discarded Methods
(i) Min-Max Scaling -- With scaling & random spliting & non-negative process, the model does not provide a better result but introducing the risk of distorting the model (extremely large error rate in prediction year of 2011)
Reason: Scaling will let the data lies in range between [0, 1], which might clash with the process of non-negative replacement by 0 since the data scale are largely changed but the replacement is still 0 (unscaled)

(ii) Input Data Merging / .tf Type Data Input Converting
This method is origianlly designed for saving computational time but both of them does not provides a good result (or a acceptable trade-off)
Reason 1: Input Data Merging helps to cut half of the model fitting time (e.g. 3.5hrs of LSTM Model Type 1 with merged data but 7 hrs for the original one). However, the error rate has significantly increased.
Reason 2: .tf Type Data Input Converting does not save any computational time but lead to redundant preprocessing of the Dataframe

(d) Potential Improvement -- All the methods below do not improve the accuracy / save the computational time
(i) Early Stopping of the LSTM Model's Fitting
When looking for the best hyperparameters, the search stops early if the validation metric stops decreasing for a certain number of epochs.
Can potentially reduce computation time, although current implementations only apply this to hyperparameter tuning.
(ii) Learning rate
Once the best hyperparameter values are obtained, the learning rate can be reduced if the validation loss stops decreasing for a certain number of epochs.
Reducing the learning rate can help the model avoid overshooting the optimum weight values, but can slow down fitting.
(iii) Different Loss Funciton
Select mean-square-error as the optimal loss function in LSTM Model Fitting rather than the mean abosolute percentage error.

================================================================================================================================================================================================================================
================================================================================================================================================================================================================================

3. LSTM_Iterative_Predict_Type3.ipynb

(a) Extra Feature
(i) Sex -- Seperate Model for LSTM Fitting and the sex should not be changed in any moment (pointless to be included)
(ii) Age -- Potentially improve the model