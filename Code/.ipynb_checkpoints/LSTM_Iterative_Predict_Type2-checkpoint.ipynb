{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnzHvGaNFij0"
   },
   "source": [
    "# LSTM Model Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LV3_kzZiFlGT",
    "outputId": "d35886fd-afb0-454f-8f5c-0c0862c5ddaf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from collections import defaultdict\n",
    "\n",
    "import keras_tuner\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from LSTM_Model_Type2 import split_position, LSTM_FitPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SwExnf-8ERZ"
   },
   "source": [
    "### Read in Raw Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xsYAM3so8ERZ"
   },
   "outputs": [],
   "source": [
    "# Read in the raw age-sex cohort data without the remainder area\n",
    "# Prepare the unique sa3 names, codes for LSTM fitting selection\n",
    "raw_data = pd.read_csv('../Data/true_1000_fulldata.csv')\n",
    "sa3_num = len(raw_data['SA3 Code'].unique())\n",
    "sa3_names = raw_data['SA3 Name'].unique()\n",
    "sa3_codes = raw_data['SA3 Code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx0WcisY8ERa"
   },
   "source": [
    "### Preprocessing by Splitting Population into Sex-Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_dLQhx9qNEbC"
   },
   "outputs": [],
   "source": [
    "# Split the data by sex\n",
    "age_groups = ['0-4','5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39','40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74','75-79', '80-84', '85+']\n",
    "population_m_dict = defaultdict(dict)\n",
    "population_f_dict = defaultdict(dict)\n",
    "\n",
    "# save population for each year into lists\n",
    "for sa3_code in sa3_codes:\n",
    "  population_m_dict[sa3_code] = dict()\n",
    "  population_f_dict[sa3_code] = dict()\n",
    "  for year in range(1991,2012):\n",
    "    if(raw_data[(raw_data['Year']==year) & (raw_data['SA3 Code']==sa3_code)]['Total'].size>0):\n",
    "      population_m_dict[sa3_code][year] = raw_data[(raw_data['Year']==year) & (raw_data['SA3 Code']==sa3_code)][['m0-4',\n",
    "                              'm5-9', 'm10-14', 'm15-19', 'm20-24', 'm25-29', 'm30-34', 'm35-39',\n",
    "                              'm40-44', 'm45-49', 'm50-54', 'm55-59', 'm60-64', 'm65-69', 'm70-74',\n",
    "                              'm75-79', 'm80-84', 'm85+']].values.tolist()[0]\n",
    "      population_f_dict[sa3_code][year] = raw_data[(raw_data['Year']==year) & (raw_data['SA3 Code']==sa3_code)][['f0-4', 'f5-9', 'f10-14', 'f15-19',\n",
    "                              'f20-24', 'f25-29', 'f30-34', 'f35-39', 'f40-44', 'f45-49', 'f50-54',\n",
    "                              'f55-59', 'f60-64', 'f65-69', 'f70-74', 'f75-79', 'f80-84', 'f85+']].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xr47JZ7Nfe1"
   },
   "source": [
    "### Create Dataframe for Storing Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "otte7EDBQLVL"
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(index = range(sa3_num*36), columns = ['Code','Area name','Sex','Age group',2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011])\n",
    "for sa3_code in range(0,sa3_num):\n",
    "  for age_group in range(18):\n",
    "    output.loc[sa3_code*36+age_group] = {'Code':sa3_codes[sa3_code],'Area name':sa3_names[sa3_code],'Sex':'Females','Age group':age_groups[age_group]}\n",
    "    output.loc[sa3_code*36+18+age_group] = {'Code':sa3_codes[sa3_code],'Area name':sa3_names[sa3_code],'Sex':'Males','Age group':age_groups[age_group]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYBKoH-u8ERc"
   },
   "source": [
    "### Start LSTM Fitting & Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmXnt5i78ERc"
   },
   "source": [
    "##### Define Variable for Splitting the Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5O0cJUJj8ERd"
   },
   "outputs": [],
   "source": [
    "# Key Year for Model Fitting\n",
    "train_start = 1991\n",
    "train_end = 2001\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 1\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 18\n",
    "n_age_groups = 18\n",
    "\n",
    "# Number of Epoch(es)\n",
    "epoch = 1000\n",
    "\n",
    "# Obtain the split position for the training sex, validation sex, and the first input_x\n",
    "train_val_bounds, test_bounds = split_position(n_steps, train_start, train_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TWSfPHk8ERd"
   },
   "source": [
    "##### LSTM Model Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g0BQl0sE8ERd"
   },
   "outputs": [],
   "source": [
    "'''Function for Defining the LSTM Model'''\n",
    "def lstm_model(lstm1_units, activ, optimizer, loss_fun):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm1_units, activation=activ, input_shape=(n_steps, n_features)))\n",
    "    model.add(Dense(n_age_groups))\n",
    "    model.compile(optimizer=optimizer, loss=loss_fun, metrics=[\"mean_absolute_percentage_error\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbbtwSoW8ERe"
   },
   "source": [
    "##### LSTM Model Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FAZMPGp38ERe"
   },
   "outputs": [],
   "source": [
    "# Define HYPERPARAMETERS\n",
    "lstm1_min = 100\n",
    "lstm1_max = 1000\n",
    "lstm1_step = 100\n",
    "activ_functions = [\"relu\"]\n",
    "optimizers = [\"adam\",\"adagrad\"]\n",
    "loss_functions = [\"mean_absolute_percentage_error\"]\n",
    "\n",
    "'''In-Build Function for LSTM Model Tuning'''\n",
    "def build_model(hp):\n",
    "    lstm1_units = hp.Int(\"LSTM units\", min_value=lstm1_min,max_value=lstm1_max,step=lstm1_step)\n",
    "    activation = hp.Choice(\"Activation Function\", activ_functions)\n",
    "    optimizer = hp.Choice(\"Optimizer\", optimizers)\n",
    "    loss_fun = hp.Choice(\"Loss Function\", loss_functions)\n",
    "    model = lstm_model(lstm1_units, activation, optimizer, loss_fun)\n",
    "    return model\n",
    "\n",
    "# Generate the tuned model with keras_tuner package\n",
    "tuner = keras_tuner.RandomSearch(hypermodel=build_model, objective=keras_tuner.Objective(\"val_mean_absolute_percentage_error\", \"min\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih-0XA4T8ERe"
   },
   "source": [
    "##### Generate Prediction Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Apcx_XuV8ERe",
    "outputId": "51e49af0-8aa2-4905-dbcf-b115a66ae91c"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2367, in get\n        return deserialize(identifier)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2322, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: nonsensical loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate each sex's Prediction Result of each age-cohort for all areas and store them into csv\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_FitPredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa3_codes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation_m_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_val_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_bounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMales\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2002\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m LSTM_FitPredict(sa3_codes, population_f_dict, n_steps, train_val_bounds, test_bounds, n_features, epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFemales\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2002\u001b[39m, tuner, output)\n\u001b[0;32m      4\u001b[0m output\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/Projection/Iterative_predict_output_Step1_1000_Type2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\Data-Science-Project\\Code\\LSTM_Model_Type2.py:56\u001b[0m, in \u001b[0;36mLSTM_FitPredict\u001b[1;34m(sa3_codes, population_dict, n_steps, train_val_bounds, test_bounds, n_features, epochs_num, sex_label, pred_start, tuner, output)\u001b[0m\n\u001b[0;32m     53\u001b[0m train_x \u001b[38;5;241m=\u001b[39m train_x\u001b[38;5;241m.\u001b[39mreshape((train_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], train_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], n_features))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Search for the best LSTM Model of this Area's data\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Fit and Record the LSTM Model based on the selected sex in the selected area\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 183\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    294\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 295\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    297\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filet_uvew04.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 272, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2367, in get\n        return deserialize(identifier)\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2322, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: nonsensical loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "# Generate each sex's Prediction Result of each age-cohort for all areas and store them into csv\n",
    "output = LSTM_FitPredict(sa3_codes, population_m_dict, n_steps, train_val_bounds, test_bounds, n_features, epoch, \"Males\", 2002, tuner, output)\n",
    "output = LSTM_FitPredict(sa3_codes, population_f_dict, n_steps, train_val_bounds, test_bounds, n_features, epoch, \"Females\", 2002, tuner, output)\n",
    "output.to_csv('../Data/Projection/Iterative_predict_output_Step1_1000_Type2.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Iterative_Predict_Type2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
